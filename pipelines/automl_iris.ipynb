{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.script_run_config import ScriptRunConfig\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.train.automl.model_proxy import ModelProxy\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "# Choose an experiment name.\r\n",
        "experiment_name = 'automl-iris'\r\n",
        "\r\n",
        "experiment = Experiment ( ws , experiment_name )\r\n",
        "\r\n",
        "output = {}\r\n",
        "output [ 'Subscription ID' ] = ws.subscription_id\r\n",
        "output [ 'Workspace Name' ] = ws.name\r\n",
        "output [ 'Resource Group' ] = ws.resource_group\r\n",
        "output [ 'Location' ] = ws.location\r\n",
        "output [ 'Experiment Name' ] = experiment.name\r\n",
        "output [ 'AMLS version' ] = azureml.core.VERSION\r\n",
        "\r\n",
        "print ( output )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Subscription ID': '4499226a-31e0-4c35-a5f4-323521d98b5b', 'Workspace Name': 'awml', 'Resource Group': 'aw', 'Location': 'eastus2', 'Experiment Name': 'automl-iris', 'AMLS version': '1.38.0'}\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv ( 'automl-iris-data/iris.csv' )\r\n",
        "train.head ()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "         class  sepal_length  sepal_width  petal_length  petal_width\n0  iris-setosa           5.1          3.5           1.4          0.2\n1  iris-setosa           4.9          3.0           1.4          0.2\n2  iris-setosa           4.7          3.2           1.3          0.2\n3  iris-setosa           4.6          3.1           1.5          0.2\n4  iris-setosa           5.0          3.6           1.4          0.2",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris-setosa</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>iris-setosa</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris-setosa</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris-setosa</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris-setosa</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test = train_test_split ( train , test_size=.2, stratify = train [ 'class' ] )\r\n",
        "data_train, data_val = train_test_split ( data_train , test_size=.25, stratify = data_train [ 'class' ] )\r\n",
        "\r\n",
        "blobstore_datadir = data_dir = 'automl-iris-data'  # Local directory to store data\r\n",
        "\r\n",
        "if not os.path.isdir ( data_dir ) :\r\n",
        "    os.mkdir ( data_dir )\r\n",
        "\r\n",
        "train_data_fname = data_dir + '/train_data.csv'\r\n",
        "val_data_fname = data_dir + '/val_data.csv'\r\n",
        "test_data_fname = data_dir + '/test_data.csv'\r\n",
        "\r\n",
        "data_train.to_csv ( train_data_fname , index = False )\r\n",
        "data_val.to_csv ( val_data_fname , index = False )\r\n",
        "data_test.to_csv ( test_data_fname , index = False )\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore ()\r\n",
        "target = DataPath (\r\n",
        "    datastore = datastore , path_on_datastore = blobstore_datadir , name = data_dir\r\n",
        ")\r\n",
        "\r\n",
        "Dataset.File.upload_directory(\r\n",
        "    src_dir = data_dir , target = target , overwrite = True , show_progress = True\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nUploading file to automl-iris-data\nUploading an estimated of 6 files\nUploading automl-iris-data/iris.csv\nUploaded automl-iris-data/iris.csv, 1 files out of an estimated total of 6\nUploading automl-iris-data/val_data.csv\nUploaded automl-iris-data/val_data.csv, 2 files out of an estimated total of 6\nUploading automl-iris-data/.amlignore\nUploaded automl-iris-data/.amlignore, 3 files out of an estimated total of 6\nUploading automl-iris-data/.amlignore.amltmp\nUploaded automl-iris-data/.amlignore.amltmp, 4 files out of an estimated total of 6\nUploading automl-iris-data/test_data.csv\nUploaded automl-iris-data/test_data.csv, 5 files out of an estimated total of 6\nUploading automl-iris-data/train_data.csv\nUploaded automl-iris-data/train_data.csv, 6 files out of an estimated total of 6\nUploaded 6 files\nCreating new dataset\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('workspaceblobstore', 'automl-iris-data')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ]\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/train_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/val_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/test_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "train_dataset = train_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_iris_data_train' ,\r\n",
        "    description = 'automl_iris_data_train' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = val_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_iris_data_val' ,\r\n",
        "    description = 'automl_iris_data_val' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = test_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_iris_data_test' ,\r\n",
        "    description = 'automl_iris_data_test' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_target = ComputeTarget ( workspace = ws , name = 'automl-training' )"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\r\n",
        "    'verbosity' : logging.INFO ,\r\n",
        "}\r\n",
        "\r\n",
        "automl_config = AutoMLConfig (\r\n",
        "    task = 'classification' ,\r\n",
        "    primary_metric = 'AUC_weighted' ,\r\n",
        "    experiment_timeout_minutes = 30 ,\r\n",
        "    debug_log= 'automl_errors.log' ,\r\n",
        "    compute_target = compute_target ,\r\n",
        "    training_data = train_dataset ,\r\n",
        "    validation_data = val_dataset ,\r\n",
        "    label_column_name = 'class' ,\r\n",
        "    **automl_settings\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_run = experiment.submit ( automl_config , show_output = False )\r\n",
        "_ = automl_run.wait_for_completion ( show_output = False )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-iris</td><td>AutoML_55c202c5-e213-4d92-8190-7694e0986a5b</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_55c202c5-e213-4d92-8190-7694e0986a5b?wsid=/subscriptions/4499226a-31e0-4c35-a5f4-323521d98b5b/resourcegroups/aw/workspaces/awml&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_metrics = automl_run.get_metrics ()\r\n",
        "validation_metrics"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "{'experiment_status': ['DatasetEvaluation',\n  'FeaturesGeneration',\n  'DatasetFeaturization',\n  'DatasetFeaturizationCompleted',\n  'ModelSelection',\n  'BestRunExplainModel',\n  'ModelExplanationDataSetSetup',\n  'PickSurrogateModel',\n  'EngineeredFeatureExplanations',\n  'EngineeredFeatureExplanations',\n  'RawFeaturesExplanations',\n  'RawFeaturesExplanations',\n  'BestRunExplainModel'],\n 'experiment_status_description': ['Gathering dataset statistics.',\n  'Generating features for the dataset.',\n  'Beginning to fit featurizers and featurize the dataset.',\n  'Completed fit featurizers and featurizing the dataset.',\n  'Beginning model selection.',\n  'Best run model explanations started',\n  'Model explanations data setup completed',\n  'Choosing LightGBM as the surrogate model for explanations',\n  'Computation of engineered features started',\n  'Computation of engineered features completed',\n  'Computation of raw features started',\n  'Computation of raw features completed',\n  'Best run model explanations completed'],\n 'recall_score_macro': 1.0,\n 'AUC_weighted': 1.0,\n 'f1_score_macro': 1.0,\n 'AUC_micro': 1.0,\n 'recall_score_weighted': 1.0,\n 'balanced_accuracy': 1.0,\n 'f1_score_micro': 1.0,\n 'average_precision_score_weighted': 1.0,\n 'precision_score_macro': 1.0,\n 'matthews_correlation': 1.0,\n 'precision_score_micro': 1.0,\n 'average_precision_score_micro': 1.0,\n 'f1_score_weighted': 1.0,\n 'norm_macro_recall': 1.0,\n 'AUC_macro': 1.0,\n 'recall_score_micro': 1.0,\n 'precision_score_weighted': 1.0,\n 'average_precision_score_macro': 1.0,\n 'weighted_accuracy': 1.0,\n 'log_loss': 0.07817057999749631,\n 'accuracy': 1.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run , best_model = automl_run.get_output ()\r\n",
        "best_run"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:The model you attempted to retrieve requires 'azureml-train-automl-runtime' to be installed at '==1.38.0'. Please install 'azureml-train-automl-runtime==1.38.0' (e.g. `pip install azureml-train-automl-runtime==1.38.0`) and then rerun the previous command.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Run(Experiment: automl-iris,\nId: AutoML_55c202c5-e213-4d92-8190-7694e0986a5b_7,\nType: None,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-iris</td><td>AutoML_55c202c5-e213-4d92-8190-7694e0986a5b_7</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_55c202c5-e213-4d92-8190-7694e0986a5b_7?wsid=/subscriptions/4499226a-31e0-4c35-a5f4-323521d98b5b/resourcegroups/aw/workspaces/awml&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_proxy = ModelProxy ( child_run = best_run , compute_target = compute_target )\r\n",
        "predictions, metrics = model_proxy.test ( test_dataset ,  include_predictions_only = True )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azureml._base_sdk_common._docstring_wrapper:Class ModelProxy: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_proxy \u001b[38;5;241m=\u001b[39m ModelProxy ( child_run \u001b[38;5;241m=\u001b[39m best_run , compute_target \u001b[38;5;241m=\u001b[39m compute_target )\n\u001b[0;32m----> 2\u001b[0m predictions, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43minclude_predictions_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/model_proxy.py:367\u001b[0m, in \u001b[0;36mModelProxy.test\u001b[0;34m(self, test_data, include_predictions_only)\u001b[0m\n\u001b[1;32m    364\u001b[0m test_run \u001b[38;5;241m=\u001b[39m Run(experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mexperiment, run_id\u001b[38;5;241m=\u001b[39mtest_run_id)\n\u001b[1;32m    365\u001b[0m test_run\u001b[38;5;241m.\u001b[39mwait_for_completion(show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, wait_post_processing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 367\u001b[0m output_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m metrics \u001b[38;5;241m=\u001b[39m test_run\u001b[38;5;241m.\u001b[39mget_metrics()\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_dataset, metrics\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/model_proxy.py:139\u001b[0m, in \u001b[0;36mModelProxy._fetch_results\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    136\u001b[0m results_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(results_locations)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results_locations) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     returned_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tabular_dataset_from_datastore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_locations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# some inference methods can return tuples, format appropriately\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     returned_values \u001b[38;5;241m=\u001b[39m ()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/model_proxy.py:118\u001b[0m, in \u001b[0;36mModelProxy._get_tabular_dataset_from_datastore\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     datastore \u001b[38;5;241m=\u001b[39m Datastore\u001b[38;5;241m.\u001b[39mget(workspace, WORKSPACE_BLOB_DATASTORE)\n\u001b[0;32m--> 118\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTabular\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_delimited_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatastore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Currently, the first parameter in this warning message\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# is a log-safe value since it is created by the SDK using\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# a predefined template with no user identifiable information in it.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# See _model_test_utilities.py::_save_results for more details.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not find the delimited file \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m in datastore: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                    \u001b[38;5;241m.\u001b[39mformat(location, WORKSPACE_BLOB_DATASTORE))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/dataset_factory.py:357\u001b[0m, in \u001b[0;36mTabularDatasetFactory.from_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    347\u001b[0m     dataflow \u001b[38;5;241m=\u001b[39m dataprep()\u001b[38;5;241m.\u001b[39mread_csv(path,\n\u001b[1;32m    348\u001b[0m                                    verify_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m                                    include_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                    empty_as_string\u001b[38;5;241m=\u001b[39mempty_as_string,\n\u001b[1;32m    355\u001b[0m                                    encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     dataflow \u001b[38;5;241m=\u001b[39m \u001b[43mdataprep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mverify_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43minclude_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43minfer_column_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_line\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m dataflow \u001b[38;5;241m=\u001b[39m _transform_and_validate(\n\u001b[1;32m    367\u001b[0m     dataflow, partition_format, include_path,\n\u001b[1;32m    368\u001b[0m     validate,\n\u001b[1;32m    369\u001b[0m     infer_column_types \u001b[38;5;129;01mor\u001b[39;00m _is_inference_required(set_column_types))\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infer_column_types:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/readers.py:100\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(path, separator, header, encoding, quoting, inference_arguments, skip_rows, skip_mode, comment, include_path, archive_options, infer_column_types, verify_exists, partition_size, empty_as_string)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mCreates a new Dataflow with the operations required to read CSV and other delimited text files (TSV, custom delimiters like semicolon, colon etc.).\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m:return: A new Dataflow.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m skip_mode \u001b[38;5;241m=\u001b[39m _default_skip_mode(skip_mode, skip_rows)\n\u001b[0;32m--> 100\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mDataflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path_to_get_files_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mparse_delimited(separator, header, encoding, quoting, skip_rows, skip_mode, comment, partition_size, empty_as_string)\n\u001b[1;32m    103\u001b[0m df \u001b[38;5;241m=\u001b[39m _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py:2454\u001b[0m, in \u001b[0;36mDataflow._path_to_get_files_block\u001b[0;34m(path, archive_options)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_datapath(path) \u001b[38;5;129;01mor\u001b[39;00m _is_datapaths(path):\n\u001b[0;32m-> 2454\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatastore_to_dataflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   2456\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py:40\u001b[0m, in \u001b[0;36mdatastore_to_dataflow\u001b[0;34m(data_source, query_timeout, is_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m datastore_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m data_source:\n\u001b[0;32m---> 40\u001b[0m     datastore, datastore_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_datastore_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fs_datastore(datastore):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedDatastoreTypeError(datastore)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py:93\u001b[0m, in \u001b[0;36mget_datastore_value\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m     90\u001b[0m path_on_storage \u001b[38;5;241m=\u001b[39m path_on_storage\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     92\u001b[0m workspace \u001b[38;5;241m=\u001b[39m datastore\u001b[38;5;241m.\u001b[39mworkspace\n\u001b[0;32m---> 93\u001b[0m \u001b[43m_set_auth_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (datastore, DatastoreValue(\n\u001b[1;32m     95\u001b[0m     subscription\u001b[38;5;241m=\u001b[39mworkspace\u001b[38;5;241m.\u001b[39msubscription_id,\n\u001b[1;32m     96\u001b[0m     resource_group\u001b[38;5;241m=\u001b[39mworkspace\u001b[38;5;241m.\u001b[39mresource_group,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath_on_storage\n\u001b[1;32m    100\u001b[0m ))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_datastore_helper.py:185\u001b[0m, in \u001b[0;36m_set_auth_type\u001b[0;34m(workspace)\u001b[0m\n\u001b[1;32m    182\u001b[0m     auth_type \u001b[38;5;241m=\u001b[39m AuthType\u001b[38;5;241m.\u001b[39mDERIVED\n\u001b[1;32m    184\u001b[0m auth_value \u001b[38;5;241m=\u001b[39m auth\n\u001b[0;32m--> 185\u001b[0m \u001b[43mget_engine_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_aml_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSetAmlAuthMessageArgument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py:38\u001b[0m, in \u001b[0;36mupdate_aml_env_vars.<locals>.decorator.<locals>.wrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(changed) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     engine_api_func()\u001b[38;5;241m.\u001b[39mupdate_environment_variable(changed)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_message_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py:290\u001b[0m, in \u001b[0;36mEngineAPI.set_aml_auth\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;129m@update_aml_env_vars\u001b[39m(get_engine_api)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_aml_auth\u001b[39m(\u001b[38;5;28mself\u001b[39m, message_args: typedefinitions\u001b[38;5;241m.\u001b[39mSetAmlAuthMessageArgument, cancellation_token: CancellationToken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_message_channel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEngine.SetAmlAuth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py:271\u001b[0m, in \u001b[0;36mMultiThreadMessageChannel.send_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_messages[message_id] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m: event, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_line(json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessageId\u001b[39m\u001b[38;5;124m'\u001b[39m: message_id,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopCode\u001b[39m\u001b[38;5;124m'\u001b[39m: op_code,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: message\n\u001b[1;32m    269\u001b[0m }, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mCustomEncoder))\n\u001b[0;32m--> 271\u001b[0m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_messages_lock:\n\u001b[1;32m    273\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_messages\u001b[38;5;241m.\u001b[39mpop(message_id, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}