{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.script_run_config import ScriptRunConfig\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print ( 'This notebook was created using version 1.39.0 of the Azure ML SDK' )\r\n",
        "print ( 'You are currently using version' , azureml.core.VERSION , 'of the Azure ML SDK' )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "# Choose an experiment name.\r\n",
        "experiment_name = 'automl-nlp-text'\r\n",
        "\r\n",
        "experiment = Experiment ( ws , experiment_name )\r\n",
        "\r\n",
        "output = {}\r\n",
        "output [ 'Subscription ID' ] = ws.subscription_id\r\n",
        "output [ 'Workspace Name' ] = ws.name\r\n",
        "output [ 'Resource Group' ] = ws.resource_group\r\n",
        "output [ 'Location' ] = ws.location\r\n",
        "output [ 'Experiment Name' ] = experiment.name\r\n",
        "\r\n",
        "print ( output )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv ( 'embold_train.csv' )\r\n",
        "train.head ()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train [ 'X' ] = ( train [ 'title' ].map ( str ) + ' ' + train [ 'body' ] ).apply ( lambda row : row.strip () ).apply ( lambda row : row [ : min ( len ( row ) , 128 ) ] )\r\n",
        "train = train.rename ( columns = { 'label' : 'y' } )\r\n",
        "train = train.drop ( [ 'title' , 'body' ] , axis = 1 ) \r\n",
        "train.head ()\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = train [ 'X' ].map ( lambda b : len ( b ) )\r\n",
        "l.describe ().T"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = train.loc [ : 20000 ]\r\n",
        "data_val = train.loc [ 20000 : 30000 ]\r\n",
        "data_test = train.loc [ 30000 : 40000]\r\n",
        "\r\n",
        "data_dir = 'automl-nlp-data'  # Local directory to store data\r\n",
        "blobstore_datadir = data_dir  # Blob store directory to store data in\r\n",
        "if not os.path.isdir ( data_dir ) :\r\n",
        "    os.mkdir ( data_dir )\r\n",
        "\r\n",
        "train_data_fname = data_dir + '/train_data.csv'\r\n",
        "val_data_fname = data_dir + '/val_data.csv'\r\n",
        "test_data_fname = data_dir + '/test_data.csv'\r\n",
        "\r\n",
        "data_train.to_csv ( train_data_fname , index = False )\r\n",
        "data_val.to_csv ( val_data_fname , index = False )\r\n",
        "data_test.to_csv ( test_data_fname , index = False )\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore ()\r\n",
        "target = DataPath (\r\n",
        "    datastore = datastore , path_on_datastore = blobstore_datadir , name = 'automl_nlp_data'\r\n",
        ")\r\n",
        "Dataset.File.upload_directory(\r\n",
        "    src_dir = data_dir , target = target , overwrite = True , show_progress = True\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/train_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/val_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = Dataset.Tabular.from_delimited_files (\r\n",
        "    path = [ ( datastore , blobstore_datadir + '/test_data.csv' ) ]\r\n",
        ")\r\n",
        "\r\n",
        "train_dataset = train_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_nlp_data_train' ,\r\n",
        "    description = 'automl_nlp_data_train' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = val_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_nlp_data_val' ,\r\n",
        "    description = 'automl_nlp_data_val' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = test_dataset.register (\r\n",
        "    workspace = ws ,\r\n",
        "    name = 'automl_nlp_data_test' ,\r\n",
        "    description = 'automl_nlp_data_test' ,\r\n",
        "    create_new_version = True ,\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_target = ComputeTarget ( workspace = ws , name = 'gpu-cluster' )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\r\n",
        "    'verbosity' : logging.INFO ,\r\n",
        "}\r\n",
        "\r\n",
        "automl_config = AutoMLConfig (\r\n",
        "    task = 'text-classification' ,\r\n",
        "    debug_log= 'automl_errors.log' ,\r\n",
        "    compute_target = compute_target ,\r\n",
        "    training_data = train_dataset ,\r\n",
        "    validation_data = val_dataset ,\r\n",
        "    label_column_name = 'y' ,\r\n",
        "    enable_dnn = True ,\r\n",
        "    **automl_settings\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_run = experiment.submit ( automl_config , show_output = False )\r\n",
        "_ = automl_run.wait_for_completion ( show_output = False )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_metrics = automl_run.get_metrics ()\r\n",
        "validation_metrics"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "{'norm_macro_recall': 0.5447819099968475,\n 'recall_score_micro': 0.7883211678832117,\n 'matthews_correlation': 0.6309329324673372,\n 'balanced_accuracy': 0.6965212733312317,\n 'AUC_macro': 0.8813928235523464,\n 'AUC_weighted': 0.8967333894421733,\n 'average_precision_score_micro': 0.8491594331191559,\n 'average_precision_score_weighted': 0.8403986060804449,\n 'recall_score_macro': 0.6965212733312317,\n 'precision_score_macro': 0.7205938149882555,\n 'f1_score_weighted': 0.7854261062053336,\n 'recall_score_weighted': 0.7883211678832117,\n 'accuracy': 0.7883211678832117,\n 'f1_score_micro': 0.7883211678832118,\n 'weighted_accuracy': 0.8160791096550282,\n 'AUC_micro': 0.9139501408323322,\n 'f1_score_macro': 0.7067028288713043,\n 'log_loss': 0.6738255217939387,\n 'average_precision_score_macro': 0.7470504065502511,\n 'precision_score_weighted': 0.7837336125451774,\n 'precision_score_micro': 0.7883211678832117}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run , best_model = automl_run.get_output () #downloading best_model might require gpu compute instance and other installs in update_env.yml\r\n",
        "best_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_run_id = best_run.id\r\n",
        "training_run = Run(experiment, training_run_id)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference script run arguments\r\n",
        "arguments = [\r\n",
        "    '--run_id' ,\r\n",
        "    training_run_id ,\r\n",
        "    '--experiment_name' ,\r\n",
        "    experiment.name ,\r\n",
        "    '--input_dataset_id',\r\n",
        "    test_dataset.as_named_input ( 'automl_nlp_data_test' ) \r\n",
        "]\r\n",
        "scoring_args = arguments\r\n",
        "\r\n",
        "with tempfile.TemporaryDirectory() as tmpdir :\r\n",
        "    # Download required files from training run into temp folder.\r\n",
        "    entry_script_name = 'score_script.py'\r\n",
        "    output_path = os.path.join ( tmpdir , entry_script_name )\r\n",
        "    training_run.download_file (\r\n",
        "        'outputs/' + entry_script_name , os.path.join ( tmpdir , entry_script_name )\r\n",
        "    )\r\n",
        "\r\n",
        "    script_run_config = ScriptRunConfig (\r\n",
        "        source_directory = tmpdir ,\r\n",
        "        script=entry_script_name ,\r\n",
        "        compute_target = compute_target ,\r\n",
        "        environment = training_run.get_environment() ,\r\n",
        "        arguments = scoring_args\r\n",
        "    )\r\n",
        "\r\n",
        "    scoring_run = experiment.submit ( script_run_config )"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ( scoring_run )\r\n",
        "_ = scoring_run.wait_for_completion ( show_output = False )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: automl-nlp-text,\nId: automl-nlp-text_1650565910_02726c34,\nType: azureml.scriptrun,\nStatus: Queued)\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_prediction_file = './preds_multiclass.csv'\r\n",
        "scoring_run.download_file (\r\n",
        "    'outputs/predictions.csv' , output_file_path = output_prediction_file\r\n",
        ")\r\n",
        "\r\n",
        "test_set_predictions_df = pd.read_csv ( 'preds_multiclass.csv' )\r\n",
        "\r\n",
        "test_data_df = test_dataset.to_pandas_dataframe ()\r\n",
        "\r\n",
        "print (\r\n",
        "    classification_report (\r\n",
        "        test_data_df [ 'y' ] , test_set_predictions_df [ 'y' ]\r\n",
        "    )\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "              precision    recall  f1-score   support\n\n           0       0.81      0.81      0.81      4434\n           1       0.81      0.84      0.82      4642\n           2       0.55      0.44      0.49       925\n\n    accuracy                           0.79     10001\n   macro avg       0.72      0.70      0.71     10001\nweighted avg       0.78      0.79      0.79     10001\n\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}